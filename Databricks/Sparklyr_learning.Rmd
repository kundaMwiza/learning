---
title: "sparkRpractice"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
# park_path <- "/usr/local/Cellar/apache-spark/2.4.5/"
# if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
#   Sys.setenv(SPARK_HOME = spark_path)
# }
# library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
# sparkR.session(master = "local[*]", sparkConfig = list(spark.driver.memory = "2g"), spark.driver.host= "127.0.0.1")

```


```{r}
# imports
# library(h2o)
library(nycflights13)
library(iris)
library(sparklyr)
library(arrow)
# library(dplyr)
library(tidyverse)

# tidyverse
library(dplyr)
library(ggplot2)
library(GGally)
library(ggpubr)

# useful
# library(mltools)
# library(data.table)
# library(SparkR)

# settings
theme_set(theme_gray(base_size = 18))
seed = 123
```

```{r}
# claim_data_path <- "/Users/mwiza/Personal/Jobs/Applications/Data scientist projects/AXA/axajuniordatascientistchallenge/data_train.csv"
# h2o.init()
# claim_df <- h2o.importFile(claim_data_path, parse= TRUE)
```

```{r}
conf <- spark_config()
sc <- spark_connect(master = "local",
                    config = conf,
                    spark.driver.host = "127.0.0.1")
```
```{r}
# head(summarize(groupBy(claim_sdf, "licence_points"), mean_claim_amount = mean(claim_sdf$target)))

```

```{r}
# claims_data_path <- "/Users/mwiza/Downloads/allstate-claims-severity/train.csv"
# claims_df <- spark_read_csv(sc =sc,path = claims_data_path, repartition = 0)
flights <- copy_to(sc, flights, "flights")
```

```{r}
repartition(claims_df, 0)
```
```{r}
iris_df <- copy_to(sc, iris, "iris")
```

