calc_func <- function(x, y =1){
return(x*y)
}
print(calc_func(2,1))
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
print(replicate(n=10, calc_func1,1))
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
print(replicate(n=10, calc_func(1,1))
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
print(replicate(n=10, calc_func(1,1)))
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
print(replicate(x=c(1,2,3,4,5,6,7,8,9,10), n=10, calc_func(y=1)))
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
print(replicate(x=c(1,2,3,4,5,6,7,8,9,10), n=10, calc_func(x=x, y=1)))
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
print(sapply(x=c(1,2,3,4,5,6,7,8,9,10), n=10, calc_func(x)))
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
print(sapply(x=c(1,2,3,4,5,6,7,8,9,10), calc_func(x)))
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
print(sapply(x=c(1,2,3,4,5,6,7,8,9,10), FUN =calc_func)
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
print(sapply(x=c(1,2,3,4,5,6,7,8,9,10), FUN =calc_func))
calc_func <- function(x, y=1){
return(x*y)
}
print(calc_func(2,1))
print(sapply(X=c(1,2,3,4,5,6,7,8,9,10), FUN =calc_func))
?rpois
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(1, 4)
rpois(3, 4)
rpois(1, 1)
rpois(1, 1)
rpois(1, 1)
rpois(1, 1)
?sd
args(sds)
args(sd)
search(Math)
search()
library(ggvis)
library("ggvis")
# if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
#
# if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
#
# pkgs <- c("RCurl","jsonlite")
#
# for (pkg in pkgs) {
#   if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
# }
#
# install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/latest_stable_R")))
# imports
library(h2o)
# tidyverse
library(dplyr)
library(ggplot2)
library(GGally)
library(ggpubr)
# useful
library(mltools)
library(data.table)
# settings
theme_set(theme_gray(base_size = 18))
seed = 123
# init h2o cluster
h2o.init(min_mem_size = "6G")
# load data
claim_data_path <- "/Users/mwiza/Personal/Jobs/Applications/Data scientist projects/AXA/axajuniordatascientistchallenge/data_train.csv"
claim_data <- h2o.importFile(path = claim_data_path, parse = TRUE)
# overview of data
summary(claim_data, exact_quantiles=TRUE)
# impute missing values
h2o.impute(claim_data, "ph_owns_home", method = "mode")
h2o.impute(claim_data, "vehicle_power", method = "mean")
h2o.impute(claim_data, "vehicle_value", method = "mean")
# map h20frame to dataframe
cdp <- as.data.frame(claim_data)
# map ph_owns_home to factor variable
cdp$ph_owns_home <- as.factor(cdp$ph_owns_home)
cdp$licence_points <- factor(cdp$licence_points, order = TRUE, levels = c(0, 3, 6))
# create pairplot
ggpairs(cdp, aes(colour=ph_owns_home, alpha = 0.4), legend = 1) +
theme(text = element_text(size=20)) +
labs(title = "Pairplot of predictor relationships")
# bin continuous features
bin_cols <- setdiff(names(claim_data), c("target", "ph_owns_home", "licence_points"))
for (i in bin_cols) {
cdp[paste(i, "bins", sep = "_")] <- cut(cdp[[i]], 10)
}
plot_bars <- list(c("licence_years_bins", "licence_years"), c("ph_age_bins", "ph_age"),
c("vehicle_power_bins", "vehicle_power"), c("vehicle_value_bins", "vehicle_value"),
c("vehicle_age_bins", "vehicle_age"), c("annual_mileage_bins", "annual_mileage"))
plot_boxs <- c("licence_points", "ph_owns_home")
plot_objects <- list()
for (i in 1:6){
plot_objects[[plot_bars[[i]][1]]] <- ggplot(cdp, aes_string(x = plot_bars[[i]][1], y = "target")) +
stat_summary(geom = "bar", fun.y = mean, position = "dodge") +
stat_summary(geom = "errorbar", fun.data = mean_se, position = "dodge") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
plot_objects[[plot_bars[[i]][2]]]<- ggplot(cdp, aes_string(x = plot_bars[[i]][2])) +
geom_histogram()
}
for (i in 1:2){
plot_objects[[paste(plot_boxs[i], "box")]]<- ggplot(cdp, aes_string(x = plot_boxs[i], y = "target")) +
geom_boxplot()
plot_objects[[paste(plot_boxs[i], "hist")]] <- ggplot(cdp, aes_string(x = plot_boxs[i])) +
geom_histogram(stat = "count")
}
ggarrange(plotlist = plot_objects,
ncol = 2, nrow = 8)
# if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
#
# if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
#
# pkgs <- c("RCurl","jsonlite")
#
# for (pkg in pkgs) {
#   if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
# }
#
# install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/latest_stable_R")))
# imports
library(h2o)
# tidyverse
library(dplyr)
library(ggplot2)
library(GGally)
library(ggpubr)
# useful
library(mltools)
library(data.table)
# settings
theme_set(theme_gray(base_size = 18))
seed = 123
# init h2o cluster
h2o.init(min_mem_size = "6G")
# load data
claim_data_path <- "/Users/mwiza/Personal/Jobs/Applications/Data scientist projects/AXA/axajuniordatascientistchallenge/data_train.csv"
claim_data <- h2o.importFile(path = claim_data_path, parse = TRUE)
# overview of data
summary(claim_data, exact_quantiles=TRUE)
# impute missing values
h2o.impute(claim_data, "ph_owns_home", method = "mode")
h2o.impute(claim_data, "vehicle_power", method = "mean")
h2o.impute(claim_data, "vehicle_value", method = "mean")
# map h20frame to dataframe
cdp <- as.data.frame(claim_data)
# map ph_owns_home to factor variable
cdp$ph_owns_home <- as.factor(cdp$ph_owns_home)
cdp$licence_points <- factor(cdp$licence_points, order = TRUE, levels = c(0, 3, 6))
# create pairplot
ggpairs(cdp, aes(colour=ph_owns_home, alpha = 0.4), legend = 1) +
theme(text = element_text(size=20)) +
labs(title = "Pairplot of predictor relationships")
# bin continuous features
bin_cols <- setdiff(names(claim_data), c("target", "ph_owns_home", "licence_points"))
for (i in bin_cols) {
cdp[paste(i, "bins", sep = "_")] <- cut(cdp[[i]], 10)
}
plot_bars <- list(c("licence_years_bins", "licence_years"), c("ph_age_bins", "ph_age"),
c("vehicle_power_bins", "vehicle_power"), c("vehicle_value_bins", "vehicle_value"),
c("vehicle_age_bins", "vehicle_age"), c("annual_mileage_bins", "annual_mileage"))
plot_boxs <- c("licence_points", "ph_owns_home")
plot_objects <- list()
for (i in 1:6){
plot_objects[[plot_bars[[i]][1]]] <- ggplot(cdp, aes_string(x = plot_bars[[i]][1], y = "target")) +
stat_summary(geom = "bar", fun.y = mean, position = "dodge") +
stat_summary(geom = "errorbar", fun.data = mean_se, position = "dodge") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
plot_objects[[plot_bars[[i]][2]]]<- ggplot(cdp, aes_string(x = plot_bars[[i]][2])) +
geom_histogram()
}
for (i in 1:2){
plot_objects[[paste(plot_boxs[i], "box")]]<- ggplot(cdp, aes_string(x = plot_boxs[i], y = "target")) +
geom_boxplot()
plot_objects[[paste(plot_boxs[i], "hist")]] <- ggplot(cdp, aes_string(x = plot_boxs[i])) +
geom_histogram(stat = "count")
}
ggarrange(plotlist = plot_objects,
ncol = 2, nrow = 8)
# some group by operation
# gb_control_list <- list(na.methods = "rm")
# mean_by_owns_house <- h2o.group_by(data = claim_data, by = "ph_owns_home", mean(), gb.control=gb_control_list)
# mean_by_owns_house
# one hot encode ph_owns_home
claim_data <- as.data.table(claim_data)
claim_data$ph_owns_home <- as.factor(claim_data$ph_owns_home)
claim_data <- one_hot(dt = claim_data, cols = c("ph_owns_home"))
claim_data <- as.h2o(claim_data)
# split data for training and testing
y <- "target"
x <- setdiff(names(claim_data), y)
ss <- h2o.splitFrame(claim_data, ratios = 0.85, seed=seed)
train <- ss[[1]]
test <- ss[[2]]
# tune RF
rf_params_1 <- list(max_depth = 10:15, min_rows = 3:8,
ntrees = seq(100, 150, 10))
rf_grid_1 <- h2o.grid("drf",x = x, y = y, training_frame = train,
hyper_params = rf_params_1, nfolds = 5,
seed = seed, grid_id = "rf_grid_1", parallelism = 0)
rf_perf_1 <- h2o.getGrid(grid_id = "rf_grid_1", decreasing = FALSE,
sort_by="mse")
# rf results
rf_perf_1
# tune GB
gbdt_params_1 <- list(learn_rate = seq(0.01, 0.12, 0.02),
max_depth = 5:15, min_rows = 5:10)
gbdt_grid_1 <- h2o.grid("gbm", x = x, y = y, training_frame = train,
hyper_params = gbdt_params_1, nfolds = 5,
seed = seed, grid_id = "gbdt_grid_1", parallelism = 0)
gbdt_perf_1 <- h2o.getGrid(grid_id = "gbdt_grid_1", decreasing = FALSE,
sort_by = "mse")
gbdt_perf_1
# tune RF
rf_params_1 <- list(max_depth = 10:15, min_rows = 3:8,
ntrees = seq(100, 150, 10))
rf_grid_1 <- h2o.grid("drf",x = x, y = y, training_frame = train,
hyper_params = rf_params_1, nfolds = 5,
seed = seed, grid_id = "rf_grid_1", parallelism = 1)
# tune RF
rf_params_1 <- list(max_depth = 10:15, min_rows = 3:8,
ntrees = seq(100, 150, 10))
rf_grid_1 <- h2o.grid("drf",x = x, y = y, training_frame = train,
hyper_params = rf_params_1, nfolds = 5,
seed = seed, grid_id = "rf_grid_1)
rf_perf_1 <- h2o.getGrid(grid_id = "rf_grid_1", decreasing = FALSE,
# tune RF
rf_params_1 <- list(max_depth = 10:15, min_rows = 3:8,
ntrees = seq(100, 150, 10))
rf_grid_1 <- h2o.grid("drf",x = x, y = y, training_frame = train,
hyper_params = rf_params_1, nfolds = 5,
seed = seed, grid_id = "rf_grid_1"")
rf_perf_1 <- h2o.getGrid(grid_id = "rf_grid_1", decreasing = FALSE,
# tune RF
rf_params_1 <- list(max_depth = 10:15, min_rows = 3:8,
ntrees = seq(100, 150, 10))
rf_grid_1 <- h2o.grid("drf",x = x, y = y, training_frame = train,
hyper_params = rf_params_1, nfolds = 5,
seed = seed, grid_id = "rf_grid_1")
# split data for training and testing
y <- "target"
x <- setdiff(names(claim_data), y)
ss <- h2o.splitFrame(claim_data, ratios = 0.85, seed=seed)
train <- ss[[1]]
test <- ss[[2]]
# tune RF
rf_params_1 <- list(max_depth = 10:15, min_rows = 3:8,
ntrees = seq(100, 150, 10))
rf_grid_1 <- h2o.grid("drf",x = x, y = y, training_frame = train,
hyper_params = rf_params_1, nfolds = 5,
seed = seed, grid_id = "rf_grid_1")
# if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
#
# if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
#
# pkgs <- c("RCurl","jsonlite")
#
# for (pkg in pkgs) {
#   if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
# }
#
# install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/latest_stable_R")))
# imports
library(h2o)
# tidyverse
library(dplyr)
library(ggplot2)
library(GGally)
library(ggpubr)
# useful
library(mltools)
library(data.table)
# settings
theme_set(theme_gray(base_size = 18))
seed = 123
# init h2o cluster
h2o.init(min_mem_size = "6G")
# load data
claim_data_path <- "/Users/mwiza/Personal/Jobs/Applications/Data scientist projects/AXA/axajuniordatascientistchallenge/data_train.csv"
claim_data <- h2o.importFile(path = claim_data_path, parse = TRUE)
# overview of data
summary(claim_data, exact_quantiles=TRUE)
# imports
library(h2o)
# tidyverse
library(dplyr)
library(ggplot2)
library(GGally)
library(ggpubr)
# useful
library(mltools)
library(data.table)
# settings
theme_set(theme_gray(base_size = 18))
seed = 123
# imports
# library(h2o)
# tidyverse
library(dplyr)
library(ggplot2)
library(GGally)
library(ggpubr)
# useful
library(mltools)
library(data.table)
# settings
theme_set(theme_gray(base_size = 18))
seed = 123
knitr::opts_chunk$set(echo = TRUE)
# imports
# library(h2o)
library(sparklyr)
library(dplyr)
# tidyverse
library(dplyr)
library(ggplot2)
library(GGally)
library(ggpubr)
# useful
# library(mltools)
# library(data.table)
# library(SparkR)
# settings
theme_set(theme_gray(base_size = 18))
seed = 123
conf <- spark_config()
sc <- spark_connect(master = "local",
config = conf)
conf <- spark_config()
sc <- spark_connect(master = "local",
config = conf)
conf <- spark_config(spark.driver.host = "127.0.0.1")
conf <- spark_config()
sc <- spark_connect(master = "local",
config = conf,
spark.driver.host = "127.0.0.1")
knitr::opts_chunk$set(echo = TRUE)
# imports
# library(h2o)
library(nycflights13)
library(sparklyr)
# library(dplyr)
library(tidyverse)
# tidyverse
library(dplyr)
library(ggplot2)
library(GGally)
library(ggpubr)
# useful
# library(mltools)
# library(data.table)
# library(SparkR)
# settings
theme_set(theme_gray(base_size = 18))
seed = 123
conf <- spark_config()
sc <- spark_connect(master = "local",
config = conf,
spark.driver.host = "127.0.0.1")
# claims_data_path <- "/Users/mwiza/Downloads/allstate-claims-severity/train.csv"
# claims_df <- spark_read_csv(sc =sc,path = claims_data_path, repartition = 0)
flights <- copy_to(sc, flights, "flights")
flights %>% drop_na
flights %>% drop_na()
flights %>% collect %>% drop_na()
library(datasets)
iris_df <- copy_to(sc, iris, "iris")
kmeans_model <- iris_tbl %>% select(Petal_Width, Petal_length) %>% ml_kmeans(centers=3)
kmeans_model <- iris_df %>% select(Petal_Width, Petal_length) %>% ml_kmeans(centers=3)
head(iris)
head(iris_df)
kmeans_model <- iris_tbl %>% select(Petal_Width, Petal_length) %>% ml_kmeans(centers=3)
kmeans_model <- iris_df %>% select(Petal_Width, Petal_length) %>% ml_kmeans(centers=3)
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ml_kmeans(centers=3)
kmeans_model <- iris_df %>% select(Petal_Width, Petal_length) %>% ml_kmeans(centers=3)
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ml_kmeans(centers=3)
rlang::last_error()
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ml_kmeans(centers = 3)
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ml_kmeans(centers = 3, features = c(Petal_Width, Petal_Length))
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ml_kmeans(k=3)
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ml_kmeans(k=3, features(Petal_Length, Petal_Width))
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ml_kmeans(k=3, features= (Petal_Length, Petal_Width))
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ml_kmeans(k=3, features = c(Petal_Length, Petal_Width))
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %$% ml_kmeans(k=3, features = c(Petal_Length, Petal_Width))
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ml_kmeans(k=3, features = c(Petal_Length, Petal_Width))
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ft_vector_assembler %>% collect
kmeans_model <- iris_df %>% select(Petal_Width, Petal_Length) %>% ft_vector_assembler(input_cols = c(Petal_Length, Petal_Width)) %>% collect
kmeans_model <- iris_df %>% ft_vector_assembler(input_cols = c(Petal_Length, Petal_Width)) %>% collect
kmeans_model <- iris_df %>% ft_vector_assembler(input_cols = c(Petal_Length, Petal_Width)) %>% collect
kmeans_model <- iris_df %$% ft_vector_assembler(input_cols = c(Petal_Length, Petal_Width)) %>% collect
kmeans_model <- iris_df %>% ft_vector_assembler(input_cols = c(.$Petal_Length, .$Petal_Width)) %>% collect
kmeans_model <- iris_df %>% ft_vector_assembler(input_cols = c("Petal_Length", "Petal_Width") %>% collect
kmeans_model <- iris_df %>% ft_vector_assembler(input_cols = c("Petal_Length", "Petal_Width")) %>% collect
kmeans_model <- iris_df %>% ft_vector_assembler(input_cols = c("Petal_Length", "Petal_Width"), output_column("features"))
kmeans_model
kmeans_model <- iris_df %>% ft_vector_assembler(input_cols = c("Petal_Length", "Petal_Width"), output_column("features")) %>% ml_kmeans(k=3)
kmeans_model
kmeans_model$summary
kmeans_model$summary$predictions
kmeans_model <- iris_df %>% select(Petal_Length, Petal_Width) %>% ft_vector_assembler(input_cols = c("Petal_Length", "Petal_Width"), output_column("features")) %>% ml_kmeans(k=3)
kmeans_model$summary
kmeans_model$summary$predictions
kmeans_model$summary$predictions %$% group_by(prediction) %>% summarize(number = n())
kmeans_model$summary$predictions %$% group_by(.$prediction) %>% summarize(number = n())
class(kmeans_model$summary$predictions )
kmeans_model$summary$predictions
kmeans_model$summary$predictions %>% group_by(prediction)
kmeans_model$summary$predictions %>% group_by(prediction) %>% summarise(count = n())
predicted %<>% kmeans_model %>% sdf_predict(iris_df) %>% collect
predicted %<>% kmeans_model %>% sdf_predict(iris_df) %>% collect
kmeans_model %>% sdf_predict(iris_df) %>% collect
kmeans_model %>% sdf_predict(., iris_df) %>% collect
kmeans_model %>% ml_predict(., iris_df) %>% collect
head(iris_df)
iris_df %<>% select(Petal_Length, Petal_Width) %>% ft_vector_assembler(input_cols=c("Petal_Width", "Petal_length"))
iris_df %<>% select(Petal_Length, Petal_Width) %>% ft_vector_assembler(input_cols=c("Petal_Width", "Petal_Length"))
head(iris_df)
iris_df %<>% select(Petal_Length, Petal_Width) %>% ft_vector_assembler(input_cols=c("Petal_Width", "Petal_Length"), output_column("features"))
head(iris_df)
kmeans_model %>% ml_predict(iris_df)
predictions %<>% kmeans_model %>% ml_predict(iris_df)
predictions <- kmeans_model %>% ml_predict(iris_df)
predictions <- kmeans_model %>% ml_predict(iris_df) %>% collect
predictions %>% ggplot(aes(Petal_Length, Petal_Width)) + geom_point()
features_df %>% select(Petal_Length, Petal_Width) %>% sdf_mutate(features = ft_vector_assembler(.,  input_cols = c("Petal_Width", "Petal_Length"))) %>% collect
features_df <- select(Petal_Length, Petal_Width) %>% sdf_mutate(features = ft_vector_assembler(.,  input_cols = c("Petal_Width", "Petal_Length"))) %>% collect
features_df <- iris_df %>% select(Petal_Length, Petal_Width) %>% sdf_mutate(features = ft_vector_assembler(.,  input_cols = c("Petal_Width", "Petal_Length"))) %>% collect
features_df <- iris_df %>% select(Petal_Length, Petal_Width) %>% mutate(features = ft_vector_assembler(.,  input_cols = c("Petal_Width", "Petal_Length"))) %>% collect
if(!file.exists("2008.csv.bz2"))
{download.file("http://stat-computing.org/dataexpo/2009/2008.csv.bz2", "2008.csv.bz2")}
if(!file.exists("2007.csv.bz2"))
{download.file("http://stat-computing.org/dataexpo/2009/2007.csv.bz2", "2007.csv.bz2")}
source("mwiza_DM_02_03.R")
dirname(parent.frame(2)$ofile)
setwd("~/Learning/machine learning/Data mining/Ex_Files_DSF_DataMining/Ex_Files_DSF_DataMining/Exercise Files/Ch2/02_03")
library(pacman)
p_load(psych) # load the psych package
p_depends(psych)
p_load(GPArotation)
# LOAD DATA
b5 <- read.csv("./data/b5.csv", header = TRUE)
boxplot(b5)
# First PCA with 5 components
principal(b5, nfactors = 5)
pc0 # check results
# First PCA with 5 components
pc0 <- principal(b5, nfactors = 5)
pc0 # check results
pc1 <- principal(b5, nfactors = 5, rotate = "oblimin")
pc1
plot(pc1)
plot(pc1)
rm(list = ls())
data.frame(mwiza = c(1:10), big_boy = c(1:10))
big <- data.frame(mwiza = c(1:10), big_boy = c(1:10))
row.names(big) = c(1:10)
big
paste("big", "big")
